// src/hooks/useVoiceInput.ts
import { useCallback, useEffect, useRef, useState } from "react";

// --- shim local minimal ---
type SpeechRec = {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start(): void;
  stop(): void;
  onstart: (() => void) | null;
  onaudiostart: (() => void) | null;
  onsoundstart: (() => void) | null;
  onspeechstart: (() => void) | null;
  onspeechend: (() => void) | null;
  onsoundend: (() => void) | null;
  onaudioend: (() => void) | null;
  onend: (() => void) | null;
  onresult: ((ev: any) => void) | null;
  onerror: ((ev: any) => void) | null;
};
type SpeechRecCtor = new () => SpeechRec;

const SR: SpeechRecCtor | null =
  typeof window !== "undefined"
    ? ((window as any).SpeechRecognition || (window as any).webkitSpeechRecognition)
    : null;

type LangOpt = "fr-FR" | "en-US" | "auto";

interface UseVoiceInputOptions {
  lang?: LangOpt;
  continuous?: boolean;
  interimResults?: boolean;
  onResult?: (text: string, detectedLang?: "fr" | "en" | "unknown") => void;
  onError?: (error: string) => void;
}

interface UseVoiceInputReturn {
  isSupported: boolean;
  isListening: boolean;
  transcript: string;
  detectedLang: "fr" | "en" | "unknown";
  startListening: () => Promise<void>;
  stopListening: () => void;
}

/** Petit helper: demande la permission micro avant SpeechRecognition.start() */
async function ensureMicPermission(): Promise<boolean> {
  if (typeof navigator === "undefined" || !navigator.mediaDevices?.getUserMedia) return true;
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    stream.getTracks().forEach((t) => t.stop());
    return true;
  } catch (e) {
    console.warn("[ZÃ‰NA] getUserMedia a Ã©chouÃ©:", e);
    return false;
  }
}

export function useVoiceInput({
  lang = "auto",
  continuous = false,
  interimResults = true,
  onResult,
  onError,
}: UseVoiceInputOptions = {}): UseVoiceInputReturn {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [detectedLang, setDetectedLang] = useState<"fr" | "en" | "unknown">("unknown");

  const isSupported = !!SR;
  const recRef = useRef<SpeechRec | null>(null);
  const onResultRef = useRef(onResult);
  const onErrorRef = useRef(onError);
  const optionsRef = useRef({ lang, continuous, interimResults });

  useEffect(() => { onResultRef.current = onResult; }, [onResult]);
  useEffect(() => { onErrorRef.current = onError; }, [onError]);
  useEffect(() => { optionsRef.current = { lang, continuous, interimResults }; }, [lang, continuous, interimResults]);

  // Instancie et cÃ¢ble les events une fois
  useEffect(() => {
    if (!isSupported || recRef.current) {
      if (!isSupported) console.warn("[ZÃ‰NA] SpeechRecognition non supportÃ© par ce navigateur.");
      return;
    }

    const recognition = new (SR as Required<typeof SR>)();
    recognition.lang = optionsRef.current.lang === "auto" ? "fr-FR" : (optionsRef.current.lang as string);
    recognition.continuous = !!optionsRef.current.continuous;
    recognition.interimResults = !!optionsRef.current.interimResults;

    // Logs dÃ©taillÃ©s
    recognition.onstart = () => console.log("ðŸŽ™ï¸ onstart");
    recognition.onaudiostart = () => console.log("ðŸ”Š onaudiostart (audio capturÃ©)");
    recognition.onsoundstart = () => console.log("ðŸŽµ onsoundstart (son dÃ©tectÃ©)");
    recognition.onspeechstart = () => console.log("ðŸ—£ï¸ onspeechstart (parole dÃ©tectÃ©e)");
    recognition.onspeechend = () => console.log("ðŸ›‘ onspeechend (fin de la parole)");
    recognition.onsoundend = () => console.log("ðŸ”‡ onsoundend (fin du son)");
    recognition.onaudioend = () => console.log("ðŸ”Œ onaudioend (fin capture audio)");

    recognition.onresult = (event: any) => {
      const res = event.results[event.resultIndex];
      const text = Array.from(res).map((r: any) => r.transcript).join("").trim();

      const en = /\b(hi|hello|how|you|thanks|please|okay|yes|no)\b/i.test(text);
      const fr = /\b(bonjour|salut|merci|oui|non|comment|Ã§a va|ca va)\b/i.test(text);
      const detected: "fr" | "en" | "unknown" = en ? "en" : fr ? "fr" : "unknown";

      setDetectedLang(detected);
      setTranscript(text);
      console.log("ðŸ“ onresult:", { text, isFinal: res.isFinal });

      if (res.isFinal) {
        onResultRef.current?.(text, detected);
        setTranscript("");
      }
    };

    recognition.onerror = (event: any) => {
      const code = event?.error || "speech_error";
      console.error("âŒ onerror:", code, event);
      setIsListening(false);

      // messages plus parlants
      const nice =
        code === "not-allowed" ? "Permission micro refusÃ©e."
        : code === "audio-capture" ? "Aucun micro dÃ©tectÃ©."
        : code === "no-speech" ? "Aucune parole dÃ©tectÃ©e."
        : code === "aborted" ? "Reconnaissance interrompue."
        : code === "network" ? "Erreur rÃ©seau."
        : code === "service-not-allowed" ? "Service de reco non autorisÃ©."
        : `Erreur reco: ${code}`;

      onErrorRef.current?.(nice);
    };

    recognition.onend = () => {
      console.log("ðŸ onend");
      if (optionsRef.current.continuous && isListening) {
        // auto-restart si on est censÃ© Ã©couter en continu
        try { recognition.start(); console.log("â†©ï¸ restart auto"); }
        catch (e) { console.warn("âš ï¸ restart Ã©chouÃ©:", e); setIsListening(false); }
      } else {
        setIsListening(false);
      }
    };

    recRef.current = recognition;
    return () => { try { recRef.current?.stop(); } catch {} recRef.current = null; };
  // ne pas dÃ©pendre de detectedLang/transcript
  }, [isSupported, isListening]);

  const startListening = useCallback(async () => {
    const rec = recRef.current;
    if (!isSupported || !rec) {
      onErrorRef.current?.("La reconnaissance vocale n'est pas supportÃ©e sur ce navigateur.");
      return;
    }

    // PrÃ©-autorise le micro pour Ã©viter not-allowed silencieux
    const ok = await ensureMicPermission();
    if (!ok) {
      onErrorRef.current?.("AccÃ¨s au micro refusÃ©. VÃ©rifie les permissions du navigateur.");
      return;
    }

    rec.lang = optionsRef.current.lang === "auto" ? "fr-FR" : (optionsRef.current.lang as string);
    rec.continuous = !!optionsRef.current.continuous;
    rec.interimResults = !!optionsRef.current.interimResults;

    try {
      (rec as any)._starting = true;
      console.log("â–¶ï¸ DÃ©marrage de l'Ã©coute");
      rec.start();
      setIsListening(true);
    } catch (e: any) {
      console.error("âŒ start() a Ã©chouÃ©:", e?.message || e);
      onErrorRef.current?.("Impossible de dÃ©marrer la reconnaissance vocale.");
      setIsListening(false);
    } finally {
      setTimeout(() => ((rec as any)._starting = false), 0);
    }
  }, [isSupported]);

  const stopListening = useCallback(() => {
    const rec = recRef.current;
    if (!rec) return;
    try {
      console.log("ðŸ›‘ ArrÃªt de l'Ã©coute");
      rec.stop();
    } finally {
      setIsListening(false);
    }
  }, []);

  return { isSupported, isListening, transcript, detectedLang, startListening, stopListening };
}
