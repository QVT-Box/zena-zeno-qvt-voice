import { useState, useRef } from "react";

export function useVoiceRecognition({ onResult, lang = "fr-FR" }) {
  const [isListening, setIsListening] = useState(false);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  const startListening = async () => {
    try {
      // ðŸ”Š VÃ©rifie la dispo du micro
      await navigator.mediaDevices.getUserMedia({ audio: true });

      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        console.warn("âš ï¸ Web Speech API non disponible â€” fallback cloud.");
        return startCloudListening();
      }

      const recognition = new SpeechRecognition();
      recognition.lang = lang;
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onstart = () => setIsListening(true);

      recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        onResult?.(text);
      };

      recognition.onerror = (event) => {
        console.error("ðŸŽ™ï¸ SpeechRecognition error:", event.error);
        setIsListening(false);
      };

      recognition.onend = () => setIsListening(false);

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error("âŒ Micro non accessible :", error);
      alert("Autorise lâ€™accÃ¨s au micro dans ton navigateur ou ta PWA.");
    }
  };

  const stopListening = () => {
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  // ðŸŒ©ï¸ Fallback cloud (Supabase â†’ Whisper)
  const startCloudListening = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const recorder = new MediaRecorder(stream);
      const chunks: Blob[] = [];

      recorder.ondataavailable = (e) => chunks.push(e.data);
      recorder.onstop = async () => {
        const blob = new Blob(chunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onloadend = async () => {
          const base64Audio = (reader.result as string).split(",")[1];

          const resp = await fetch(
            "https://mahmakmfonycckirgtwm.supabase.co/functions/v1/speech-to-text",
            {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ audio: base64Audio, mimeType: "audio/webm" }),
            }
          );

          const data = await resp.json();
          if (data.text) onResult?.(data.text);
        };
        reader.readAsDataURL(blob);
      };

      recorder.start();
      setIsListening(true);
      setTimeout(() => {
        recorder.stop();
        setIsListening(false);
      }, 5000); // Ã©coute 5 secondes
    } catch (err) {
      console.error("ðŸŽ¤ Fallback cloud error:", err);
    }
  };

  return { isListening, startListening, stopListening };
}
