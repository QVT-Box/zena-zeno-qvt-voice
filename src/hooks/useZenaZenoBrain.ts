import { useState, useEffect, useRef } from "react";
import { useZenaVoice } from "@/hooks/useZenaVoice";

interface Message {
  from: "user" | "zena";
  text: string;
}

interface EmotionalState {
  mood: "positive" | "negative" | "neutral";
  score: number;
}

interface RecommendedBox {
  name: string;
  theme: string;
  description: string;
}

interface UseZenaZenoBrainOptions {
  persona: "zena" | "zeno";
  language?: "auto" | "fr-FR" | "en-US";
}

/**
 * üß† useZenaZenoBrain
 * ------------------------------------------------------
 * Cerveau IA unifi√© :
 * - √âcoute le texte utilisateur (via VoiceControl)
 * - G√©n√®re une r√©ponse √©motionnelle (locale)
 * - Parle avec la voix correspondante (useZenaVoice)
 * - G√®re les √©motions + recommandations de box
 */
export function useZenaZenoBrain({
  persona = "zena",
  language = "auto",
}: UseZenaZenoBrainOptions) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [thinking, setThinking] = useState(false);
  const [emotionalState, setEmotionalState] = useState<EmotionalState>({
    mood: "neutral",
    score: 8,
  });
  const [recommendedBox, setRecommendedBox] = useState<RecommendedBox | null>(null);
  const [transcript, setTranscript] = useState("");
  const { say, isSpeaking, audioLevel } = useZenaVoice({
    lang: language === "auto" ? "fr-FR" : language,
    gender: persona === "zena" ? "female" : "male",
  });
  const [isListening, setIsListening] = useState(false);

  const stopRef = useRef(false);

  /**
   * ‚úçÔ∏è Simulation d'une r√©ponse √©motionnelle IA
   */
  const generateAIResponse = async (userText: string): Promise<string> => {
    const lower = userText.toLowerCase();
    let response = "";
    let mood: EmotionalState["mood"] = "neutral";
    let score = 8;
    let box: RecommendedBox | null = null;

    if (lower.includes("stress") || lower.includes("fatigue")) {
      response =
        persona === "zena"
          ? "Je ressens un peu de tension dans ta voix. Prends un instant pour respirer profond√©ment üí®"
          : "Je comprends, la fatigue peut peser lourd. Un peu de recul t‚Äôaiderait.";
      mood = "negative";
      score = 5;
      box = {
        name: "Box Relax & Respire",
        theme: "D√©tente & S√©r√©nit√©",
        description: "Une box pens√©e pour apaiser le mental et retrouver ton calme.",
      };
    } else if (lower.includes("bien") || lower.includes("motiv√©")) {
      response =
        persona === "zena"
          ? "√áa me fait plaisir de te sentir dans une bonne √©nergie üåû"
          : "Excellente vibe aujourd‚Äôhui, continue sur cette lanc√©e !";
      mood = "positive";
      score = 12;
      box = {
        name: "Box Vitalit√© & Motivation",
        theme: "√ânergie & Confiance",
        description: "Des produits pour entretenir ta belle √©nergie !",
      };
    } else {
      response =
        persona === "zena"
          ? "Merci pour ton partage. Dis-m‚Äôen un peu plus sur ce que tu ressens ? üí¨"
          : "Je t‚Äô√©coute, veux-tu approfondir un peu ce que tu ressens ?";
      mood = "neutral";
      score = 8;
      box = null;
    }

    await new Promise((r) => setTimeout(r, 1500)); // simulation de r√©flexion

    setEmotionalState({ mood, score });
    setRecommendedBox(box);
    return response;
  };

  /**
   * üéß Quand l‚Äôutilisateur parle
   */
  const onUserSpeak = async (text: string) => {
    if (!text || stopRef.current) return;
    setTranscript(text);
    setMessages((prev) => [...prev, { from: "user", text }]);
    setThinking(true);

    const aiResponse = await generateAIResponse(text);
    setThinking(false);
    setMessages((prev) => [...prev, { from: persona, text: aiResponse }]);

    say(aiResponse);
  };

  /**
   * üé§ √âtat d‚Äô√©coute (li√© √† VoiceControl)
   */
  const startListening = () => setIsListening(true);
  const stopListening = () => setIsListening(false);

  return {
    messages,
    emotionalState,
    recommendedBox,
    isListening,
    startListening,
    stopListening,
    onUserSpeak,
    speaking: isSpeaking,
    thinking,
    transcript,
    audioLevel,
  };
}
