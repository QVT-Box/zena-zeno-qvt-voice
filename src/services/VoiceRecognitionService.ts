/**
 * üé§ Service de reconnaissance vocale modulaire
 * Compatible mobile/desktop et pr√™t pour l'int√©gration cloud
 */

export type VoiceRecognitionMode = 'browser' | 'cloud';

export interface VoiceRecognitionOptions {
  lang?: string;
  continuous?: boolean;
  interimResults?: boolean;
  onResult?: (text: string, isFinal: boolean) => void;
  onError?: (error: string) => void;
  onStart?: () => void;
  onEnd?: () => void;
}

export interface IVoiceRecognitionService {
  isSupported(): boolean;
  start(): Promise<void>;
  stop(): void;
  isListening(): boolean;
}

/**
 * Service de reconnaissance bas√© sur Web Speech API (navigateur)
 */
export class BrowserVoiceRecognition implements IVoiceRecognitionService {
  private recognition: SpeechRecognition | null = null;
  private listening = false;
  private options: VoiceRecognitionOptions;

  constructor(options: VoiceRecognitionOptions) {
    this.options = options;
    this.initRecognition();
  }

  private initRecognition() {
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.warn("‚ö†Ô∏è Web Speech API non support√©e");
      return;
    }

    this.recognition = new SpeechRecognition();
    this.recognition.lang = this.options.lang || 'fr-FR';
    this.recognition.continuous = this.options.continuous || false;
    this.recognition.interimResults = this.options.interimResults || true;
    // @ts-ignore - maxAlternatives existe mais n'est pas dans les types TS
    this.recognition.maxAlternatives = 1;

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      let transcript = "";
      let isFinal = false;

      for (let i = event.resultIndex; i < event.results.length; i++) {
        transcript += event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          isFinal = true;
        }
      }

      if (transcript.trim()) {
        this.options.onResult?.(transcript.trim(), isFinal);
      }
    };

    this.recognition.onerror = (event: any) => {
      console.error("‚ùå Erreur reconnaissance:", event.error);
      
      const errorMessages: { [key: string]: string } = {
        "not-allowed": "Permission du microphone refus√©e",
        "no-speech": "Aucune parole d√©tect√©e",
        "audio-capture": "Microphone non disponible",
        "network": "Erreur r√©seau",
        "aborted": "Reconnaissance interrompue"
      };

      this.options.onError?.(errorMessages[event.error] || event.error);
      this.listening = false;
    };

    this.recognition.onend = () => {
      console.log("üî¥ Reconnaissance arr√™t√©e");
      this.listening = false;
      this.options.onEnd?.();
    };

    // @ts-ignore - onstart existe mais n'est pas dans les types TS standard
    this.recognition.onstart = () => {
      console.log("üü¢ Reconnaissance d√©marr√©e");
      this.listening = true;
      this.options.onStart?.();
    };
  }

  isSupported(): boolean {
    return !!((window as any).SpeechRecognition || (window as any).webkitSpeechRecognition);
  }

  async start(): Promise<void> {
    if (!this.recognition) {
      throw new Error("Reconnaissance vocale non disponible");
    }

    if (this.listening) {
      console.warn("‚ö†Ô∏è D√©j√† en √©coute");
      return;
    }

    try {
      // Sur mobile/desktop, laisser Web Speech API g√©rer le micro
      // Ne PAS utiliser getUserMedia manuellement car √ßa cr√©e des conflits/√©chos
      console.log("üé§ D√©marrage reconnaissance vocale...");
      this.recognition.start();
      
    } catch (err: any) {
      console.error("‚ùå Erreur d√©marrage:", err);
      
      let errorMessage = "Impossible de d√©marrer la reconnaissance vocale";
      
      if (err.name === "NotAllowedError" || err.name === "PermissionDeniedError") {
        errorMessage = "Permission du microphone refus√©e. V√©rifiez les param√®tres de votre navigateur.";
      } else if (err.name === "NotSupportedError") {
        errorMessage = "Reconnaissance vocale non support√©e sur ce navigateur. Essayez Chrome.";
      } else if (err.message?.includes("already started")) {
        errorMessage = "Reconnaissance d√©j√† en cours";
      }
      
      throw new Error(errorMessage);
    }
  }

  stop(): void {
    if (this.recognition && this.listening) {
      try {
        this.recognition.stop();
      } catch (err) {
        console.warn("Erreur lors de l'arr√™t:", err);
      }
    }
    this.listening = false;
  }

  isListening(): boolean {
    return this.listening;
  }
}

/**
 * Service de reconnaissance bas√© sur le cloud (OpenAI Realtime API)
 * √Ä impl√©menter plus tard
 */
export class CloudVoiceRecognition implements IVoiceRecognitionService {
  private options: VoiceRecognitionOptions;
  private listening = false;

  constructor(options: VoiceRecognitionOptions) {
    this.options = options;
  }

  isSupported(): boolean {
    // TODO: v√©rifier si l'API cloud est disponible
    return false;
  }

  async start(): Promise<void> {
    // TODO: impl√©menter avec OpenAI Realtime API
    throw new Error("Cloud voice recognition pas encore impl√©ment√©");
  }

  stop(): void {
    // TODO: impl√©menter
    this.listening = false;
  }

  isListening(): boolean {
    return this.listening;
  }
}

/**
 * Factory pour cr√©er le bon service selon la disponibilit√©
 */
export class VoiceRecognitionFactory {
  static create(
    mode: VoiceRecognitionMode,
    options: VoiceRecognitionOptions
  ): IVoiceRecognitionService {
    if (mode === 'cloud') {
      return new CloudVoiceRecognition(options);
    }
    return new BrowserVoiceRecognition(options);
  }

  static getBestAvailableMode(): VoiceRecognitionMode {
    const browserRecognition = new BrowserVoiceRecognition({});
    if (browserRecognition.isSupported()) {
      return 'browser';
    }
    return 'cloud'; // Fallback vers le cloud si le navigateur ne supporte pas
  }
}
