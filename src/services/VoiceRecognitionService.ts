/**
 * üé§ VoiceRecognitionService ‚Äì version mobile-friendly
 * Compatibilit√© totale Chrome / Safari / Android / iOS (PWA)
 * et meilleure gestion des sessions et permissions.
 */

export type VoiceRecognitionMode = "browser" | "cloud";

export interface VoiceRecognitionOptions {
  lang?: string;
  continuous?: boolean;
  interimResults?: boolean;
  onResult?: (text: string, isFinal: boolean) => void;
  onError?: (error: string) => void;
  onStart?: () => void;
  onEnd?: () => void;
}

export interface IVoiceRecognitionService {
  isSupported(): boolean;
  start(): Promise<void>;
  stop(): void;
  isListening(): boolean;
}

/**
 * üß† Web Speech API (navigateur)
 */
export class BrowserVoiceRecognition implements IVoiceRecognitionService {
  private recognition: SpeechRecognition | null = null;
  private listening = false;
  private options: VoiceRecognitionOptions;

  constructor(options: VoiceRecognitionOptions) {
    this.options = options;
    this.initRecognition();
  }

  private initRecognition() {
    const SpeechRecognition =
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.warn("‚ö†Ô∏è Web Speech API non support√©e sur ce navigateur");
      return;
    }

    this.recognition = new SpeechRecognition();
    this.recognition.lang = this.options.lang || "fr-FR";
    this.recognition.continuous = this.options.continuous || false;
    this.recognition.interimResults = this.options.interimResults || true;
    // @ts-ignore
    this.recognition.maxAlternatives = 1;

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      let transcript = "";
      let isFinal = false;
      for (let i = event.resultIndex; i < event.results.length; i++) {
        transcript += event.results[i][0].transcript;
        if (event.results[i].isFinal) isFinal = true;
      }
      if (transcript.trim()) this.options.onResult?.(transcript.trim(), isFinal);
    };

    this.recognition.onerror = (event: any) => {
      console.error("‚ùå SpeechRecognition error:", event.error);
      const messages: Record<string, string> = {
        "not-allowed": "Permission du micro refus√©e",
        "no-speech": "Aucune parole d√©tect√©e",
        "audio-capture": "Micro non disponible",
        "network": "Erreur r√©seau",
        "aborted": "Session interrompue",
      };
      this.options.onError?.(messages[event.error] || event.error);
      this.listening = false;
      this.options.onEnd?.();
    };

    this.recognition.onend = () => {
      this.listening = false;
      this.options.onEnd?.();
    };

    // @ts-ignore
    this.recognition.onstart = () => {
      this.listening = true;
      this.options.onStart?.();
    };
  }

  isSupported(): boolean {
    return !!(
      (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
    );
  }

  async start(): Promise<void> {
    if (!this.recognition) throw new Error("Reconnaissance vocale non disponible");

    if (this.listening) {
      console.warn("‚ö†Ô∏è D√©j√† en √©coute, red√©marrage propre...");
      this.stop();
      await new Promise((r) => setTimeout(r, 500));
    }

    try {
      console.log("üé§ Demande de permission micro...");
      await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log("‚úÖ Micro autoris√©, lancement √©coute...");

      // Safari iOS : n√©cessite un d√©clenchement synchronis√© avec un clic
      setTimeout(() => {
        try {
          this.recognition?.start();
        } catch (e) {
          console.error("‚ö†Ô∏è Impossible de d√©marrer recognition.start()", e);
        }
      }, 150);
    } catch (err: any) {
      let msg = "Erreur microphone";
      if (err.name === "NotAllowedError")
        msg = "Permission du micro refus√©e.";
      else if (err.name === "NotFoundError")
        msg = "Aucun micro d√©tect√©.";
      this.options.onError?.(msg);
      throw new Error(msg);
    }
  }

  stop(): void {
    if (this.recognition) {
      try {
        this.recognition.stop();
      } catch {}
    }
    this.listening = false;
  }

  isListening(): boolean {
    return this.listening;
  }
}

/**
 * ‚òÅÔ∏è Mode cloud (fallback, API STT)
 * ‚Äì fonctionne sur iOS Safari
 * ‚Äì √† connecter plus tard √† ton endpoint Whisper
 */
export class CloudVoiceRecognition implements IVoiceRecognitionService {
  private listening = false;
  private options: VoiceRecognitionOptions;
  private stream: MediaStream | null = null;
  private recorder: MediaRecorder | null = null;
  private chunks: Blob[] = [];

  constructor(options: VoiceRecognitionOptions) {
    this.options = options;
  }

  isSupported(): boolean {
    return typeof MediaRecorder !== "undefined";
  }

  async start(): Promise<void> {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.recorder = new MediaRecorder(this.stream);
      this.chunks = [];

      this.recorder.ondataavailable = (e) => {
        if (e.data.size > 0) this.chunks.push(e.data);
      };
      this.recorder.onstop = async () => {
        const blob = new Blob(this.chunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onloadend = () => {
          console.log("üéß Fichier audio pr√™t pour cloud STT");
          // üëâ √† connecter plus tard √† Supabase Edge / Whisper
          this.options.onError?.(
            "Mode cloud actif ‚Äî transcription non encore connect√©e"
          );
        };
        reader.readAsDataURL(blob);
        this.listening = false;
        this.options.onEnd?.();
      };

      this.recorder.start();
      this.listening = true;
      this.options.onStart?.();
    } catch (err) {
      console.error("‚ùå CloudVoiceRecognition error:", err);
      this.options.onError?.("Erreur d'acc√®s au micro");
      throw err;
    }
  }

  stop(): void {
    if (this.recorder && this.listening) {
      this.recorder.stop();
    }
    this.stream?.getTracks().forEach((t) => t.stop());
    this.listening = false;
  }

  isListening(): boolean {
    return this.listening;
  }
}

/**
 * üß© Factory intelligente
 */
export class VoiceRecognitionFactory {
  static create(mode: VoiceRecognitionMode, options: VoiceRecognitionOptions) {
    return mode === "cloud"
      ? new CloudVoiceRecognition(options)
      : new BrowserVoiceRecognition(options);
  }

  static getBestAvailableMode(): VoiceRecognitionMode {
    const isIOS = /iPhone|iPad|iPod|CriOS|Safari/.test(navigator.userAgent);
    const browserSupported =
      !!(window as any).SpeechRecognition ||
      !!(window as any).webkitSpeechRecognition;
    if (isIOS && !browserSupported) return "cloud";
    return browserSupported ? "browser" : "cloud";
  }
}
