// ===========================================================
// üåø Z√âNA - IA √âMOTIONNELLE QVT BOX
// Triple fallback : OpenAI ‚Üí Mistral ‚Üí Mode local (autonome)
// ===========================================================

import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

// ===========================================================
// ‚öôÔ∏è CONFIGURATION
// ===========================================================
const corsHeaders = {
  "Access-Control-Allow-Origin": "https://zena.qvtbox.com",
  "Access-Control-Allow-Methods": "POST, OPTIONS",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

const supa = createClient(
  Deno.env.get("SUPABASE_URL")!,
  Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!
);

const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const MISTRAL_API_KEY = Deno.env.get("MISTRAL_API_KEY");
const OPENAI_MODEL = "gpt-4o-mini";
const MISTRAL_MODEL = "mistral-tiny";

// ===========================================================
// ‚ù§Ô∏è ANALYSE √âMOTIONNELLE LOCALE (fallback offline)
// ===========================================================
function localEmotionAnalysis(text: string) {
  const t = text.toLowerCase();
  let emotion = "neutre", besoin = "sens", intensit√© = 0.4, ton = "calme";

  if (/(fatigu|√©puis|burnout|lass√©)/.test(t)) {
    emotion = "fatigue"; besoin = "repos"; intensit√© = 0.8; ton = "doux";
  } else if (/(stress|angoiss|tendu|inquiet)/.test(t)) {
    emotion = "stress"; besoin = "soutien"; intensit√© = 0.7; ton = "rassurant";
  } else if (/(triste|seul|d√©prim√©)/.test(t)) {
    emotion = "tristesse"; besoin = "lien"; intensit√© = 0.9; ton = "chaleureux";
  } else if (/(col√®r|√©nerv|frustr√©)/.test(t)) {
    emotion = "col√®re"; besoin = "reconnaissance"; intensit√© = 0.8; ton = "calme";
  } else if (/(motiv√©|heureux|bien|content|serein)/.test(t)) {
    emotion = "joie"; besoin = "partage"; intensit√© = 0.6; ton = "positif";
  }

  return { emotion_dominante: emotion, intensit√©, besoin, ton_recommand√©: ton };
}

// ===========================================================
// üé≠ PERSONA SYSTEM
// ===========================================================
function personaSystem(p: "zena" | "zeno" = "zena", lang: "fr" | "en" = "fr") {
  const zenaFR = `Tu es Z√âNA, intelligence √©motionnelle de QVT Box.
Tu √©coutes, reformules avec douceur et aides √† retrouver sens et √©nergie.
Ton style est humain, fluide, apaisant et sinc√®re.`;

  const zenoFR = `Tu es Z√âNO, coach analytique QVT.
Tu aides √† comprendre calmement les causes des difficult√©s et √† les r√©soudre.`;

  const zenaEN = `You are Z√âNA, the emotional intelligence of QVT Box.
You listen deeply, respond warmly, and guide with care.`;

  return lang === "en" ? zenaEN : p === "zena" ? zenaFR : zenoFR;
}

// ===========================================================
// üß† ANALYSE √âMOTIONNELLE VIA OPENAI / MISTRAL
// ===========================================================
async function analyzeEmotion(text: string, lang: "fr" | "en") {
  const prompt = lang === "fr"
    ? `Analyse ce message et renvoie un JSON :
- emotion_dominante : [joie, calme, stress, tristesse, col√®re, fatigue, isolement]
- intensit√© : 0‚Äì1
- besoin : (repos, reconnaissance, soutien, sens, lien)
- ton_recommand√© : (rassurant, motivant, calme, doux, √©nergisant)
Message : """${text}"""
R√©ponds uniquement en JSON.`
    : `Analyze this message emotionally. Return JSON with dominant_emotion, intensity, need, tone_hint.`;

  // 1Ô∏è‚É£ Tentative OpenAI
  if (OPENAI_API_KEY) {
    try {
      const r = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${OPENAI_API_KEY}` },
        body: JSON.stringify({
          model: OPENAI_MODEL,
          messages: [{ role: "user", content: prompt }],
          temperature: 0.3,
        }),
      });
      const j = await r.json();
      const raw = j.choices?.[0]?.message?.content || "";
      return JSON.parse(raw);
    } catch (err) {
      console.warn("[ZENA] ‚ö†Ô∏è OpenAI failed:", err.message);
    }
  }

  // 2Ô∏è‚É£ Tentative Mistral
  if (MISTRAL_API_KEY) {
    try {
      const r = await fetch("https://api.mistral.ai/v1/chat/completions", {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${MISTRAL_API_KEY}` },
        body: JSON.stringify({
          model: MISTRAL_MODEL,
          messages: [{ role: "user", content: prompt }],
          temperature: 0.4,
        }),
      });
      const j = await r.json();
      const raw = j.choices?.[0]?.message?.content || "";
      return JSON.parse(raw);
    } catch (err) {
      console.warn("[ZENA] ‚ö†Ô∏è Mistral failed:", err.message);
    }
  }

  // 3Ô∏è‚É£ Fallback local
  console.warn("[ZENA] ‚öôÔ∏è Using local emotion analysis fallback");
  return localEmotionAnalysis(text);
}

// ===========================================================
// üí¨ R√âPONSE (OpenAI ‚Üí Mistral ‚Üí Locale)
// ===========================================================
async function generateResponse(text: string, analysis: any, persona: string, lang: string) {
  const prompt =
    lang === "fr"
      ? `${personaSystem(persona, lang)}

Message utilisateur : "${text}"
√âmotion d√©tect√©e : ${analysis.emotion_dominante}
Besoin : ${analysis.besoin}
Adopte un ton ${analysis.ton_recommand√©}.
R√©ponds en 2 phrases maximum, avec chaleur et authenticit√©.`
      : `User says: "${text}". Respond kindly in English, in two short sentences.`;

  // 1Ô∏è‚É£ OpenAI
  if (OPENAI_API_KEY) {
    try {
      const r = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${OPENAI_API_KEY}` },
        body: JSON.stringify({ model: OPENAI_MODEL, messages: [{ role: "user", content: prompt }], temperature: 0.7 }),
      });
      const j = await r.json();
      return j.choices?.[0]?.message?.content?.trim() ?? "Je t‚Äô√©coute ";
    } catch (e) {
      console.warn("[ZENA] OpenAI reply failed ‚Üí fallback Mistral");
    }
  }

  // 2Ô∏è‚É£ Mistral
  if (MISTRAL_API_KEY) {
    try {
      const r = await fetch("https://api.mistral.ai/v1/chat/completions", {
        method: "POST",
        headers: { "Content-Type": "application/json", Authorization: `Bearer ${MISTRAL_API_KEY}` },
        body: JSON.stringify({ model: MISTRAL_MODEL, messages: [{ role: "user", content: prompt }], temperature: 0.7 }),
      });
      const j = await r.json();
      return j.choices?.[0]?.message?.content?.trim() ?? "Je t‚Äô√©coute ";
    } catch (e) {
      console.warn("[ZENA] Mistral reply failed ‚Üí fallback local");
    }
  }

  // 3Ô∏è‚É£ Local
  return `Je ressens ${analysis.emotion_dominante}. Peut-√™tre qu‚Äôun instant pour toi aiderait √† retrouver ${analysis.besoin} üí´`;
}

// ===========================================================
// üß© HANDLER PRINCIPAL
// ===========================================================
serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response("ok", { status: 200, headers: corsHeaders });
  }

  try {
    const { text, persona = "zena", lang = "fr" } = await req.json();

    if (!text?.trim()) {
      return new Response(JSON.stringify({ error: "missing text" }), { status: 400, headers: corsHeaders });
    }

    const emotional = await analyzeEmotion(text, lang);
    const reply = await generateResponse(text, emotional, persona, lang);

    return new Response(JSON.stringify({ reply, emotional }), {
      status: 200,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  } catch (err) {
    console.error("[ZENA] ‚ùå Fatal error:", err);
    return new Response(JSON.stringify({ error: err?.message || "Unexpected error" }), {
      status: 200,
      headers: corsHeaders,
    });
  }
});
